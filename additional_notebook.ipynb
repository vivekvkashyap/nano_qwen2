{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b3c1ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-29 18:22:28,741] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ece/anaconda3/envs/tf-gpu-211/bin/../lib/gcc/x86_64-conda-linux-gnu/11.2.0/../../../../x86_64-conda-linux-gnu/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/home/ece/anaconda3/envs/tf-gpu-211/bin/../lib/gcc/x86_64-conda-linux-gnu/11.2.0/../../../../x86_64-conda-linux-gnu/bin/ld: cannot find -lcufile: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ecc6b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-29 18:36:10,713] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ece/anaconda3/envs/tf-gpu-211/bin/../lib/gcc/x86_64-conda-linux-gnu/11.2.0/../../../../x86_64-conda-linux-gnu/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/home/ece/anaconda3/envs/tf-gpu-211/bin/../lib/gcc/x86_64-conda-linux-gnu/11.2.0/../../../../x86_64-conda-linux-gnu/bin/ld: cannot find -lcufile: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62c9a366ae3d49a896257cf8d694f358",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/660 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03e9fc6b71b44357963dc7a212d34e4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.09G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56acb3d93cda48dd9120b00ea1e723a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98c5940b2c3043359942b338aa8bf5d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d92639a1a814ef7be499588dfd99642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a5b01dc73444742a1d63d6966eca350",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4ba5b07efc346faba1951968ddae9a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen2 is a research project by Alibaba Cloud and Baidu AI that aims to develop an advanced natural language processing (NLP) system based on the Transformer architecture, which was invented by Google in 2017.\n",
      "\n",
      "The Qwen2 model family consists of several models, including:\n",
      "\n",
      "  * Qwen: The first model in the series, which was released in December 2021.\n",
      "  * Qwen-1B: A larger version of the Qwen model, with over one billion parameters.\n",
      "  * Qwen-3B: An even larger version of the Qwen model, with over three billion parameters.\n",
      "\n",
      "All Qwen2 models use the same Transformer architecture but are optimized for different tasks such as text generation, summarization, machine translation, and question answering.\n",
      "\n",
      "The Qwen2 models are trained using large amounts of text data from various sources, including news articles, scientific papers, books, and social media posts. The models are designed to be highly efficient and scalable, meaning they can handle massive amounts of input data and process it quickly without consuming excessive computing resources.\n",
      "\n",
      "Overall, the Qwen2 model family represents a significant advancement in NLP technology and has the potential to revolutionize how we interact with language-based content in the coming years.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\n",
    "    task=\"text-generation\",\n",
    "    model=\"Qwen/Qwen2-1.5B-Instruct\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=0\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me about the Qwen2 model family.\"},\n",
    "]\n",
    "outputs = pipe(messages, max_new_tokens=256, do_sample=True, temperature=0.7, top_k=50, top_p=0.95)\n",
    "print(outputs[0][\"generated_text\"][-1]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4a0eb00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-30 18:23:51,854] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ece/anaconda3/envs/tf-gpu-211/bin/../lib/gcc/x86_64-conda-linux-gnu/11.2.0/../../../../x86_64-conda-linux-gnu/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/home/ece/anaconda3/envs/tf-gpu-211/bin/../lib/gcc/x86_64-conda-linux-gnu/11.2.0/../../../../x86_64-conda-linux-gnu/bin/ld: cannot find -lcufile: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    }
   ],
   "source": [
    "from transformers import Qwen2Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f18405a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ca1fc5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    }
   ],
   "source": [
    "model_hf = Qwen2Model.from_pretrained('Qwen/Qwen2-0.5B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3292cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer import Qwen2LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "49ec887b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "embed_tokens.weight torch.Size([151936, 896])\n",
      "1\n",
      "layers.0.self_attn.q_proj.weight torch.Size([896, 896])\n",
      "2\n",
      "layers.0.self_attn.q_proj.bias torch.Size([896])\n",
      "3\n",
      "layers.0.self_attn.k_proj.weight torch.Size([128, 896])\n",
      "4\n",
      "layers.0.self_attn.k_proj.bias torch.Size([128])\n",
      "5\n",
      "layers.0.self_attn.v_proj.weight torch.Size([128, 896])\n",
      "6\n",
      "layers.0.self_attn.v_proj.bias torch.Size([128])\n",
      "7\n",
      "layers.0.self_attn.o_proj.weight torch.Size([896, 896])\n",
      "8\n",
      "layers.0.mlp.gate_proj.weight torch.Size([4864, 896])\n",
      "9\n",
      "layers.0.mlp.up_proj.weight torch.Size([4864, 896])\n",
      "10\n",
      "layers.0.mlp.down_proj.weight torch.Size([896, 4864])\n",
      "11\n",
      "layers.0.input_layernorm.weight torch.Size([896])\n",
      "12\n",
      "layers.0.post_attention_layernorm.weight torch.Size([896])\n",
      "13\n",
      "layers.1.self_attn.q_proj.weight torch.Size([896, 896])\n",
      "14\n",
      "layers.1.self_attn.q_proj.bias torch.Size([896])\n",
      "15\n",
      "layers.1.self_attn.k_proj.weight torch.Size([128, 896])\n",
      "16\n",
      "layers.1.self_attn.k_proj.bias torch.Size([128])\n",
      "17\n",
      "layers.1.self_attn.v_proj.weight torch.Size([128, 896])\n",
      "18\n",
      "layers.1.self_attn.v_proj.bias torch.Size([128])\n",
      "19\n",
      "layers.1.self_attn.o_proj.weight torch.Size([896, 896])\n",
      "20\n",
      "layers.1.mlp.gate_proj.weight torch.Size([4864, 896])\n",
      "21\n",
      "layers.1.mlp.up_proj.weight torch.Size([4864, 896])\n",
      "22\n",
      "layers.1.mlp.down_proj.weight torch.Size([896, 4864])\n",
      "23\n",
      "layers.1.input_layernorm.weight torch.Size([896])\n",
      "24\n",
      "layers.1.post_attention_layernorm.weight torch.Size([896])\n",
      "25\n",
      "layers.2.self_attn.q_proj.weight torch.Size([896, 896])\n",
      "26\n",
      "layers.2.self_attn.q_proj.bias torch.Size([896])\n",
      "27\n",
      "layers.2.self_attn.k_proj.weight torch.Size([128, 896])\n",
      "28\n",
      "layers.2.self_attn.k_proj.bias torch.Size([128])\n",
      "29\n",
      "layers.2.self_attn.v_proj.weight torch.Size([128, 896])\n",
      "30\n",
      "layers.2.self_attn.v_proj.bias torch.Size([128])\n",
      "31\n",
      "layers.2.self_attn.o_proj.weight torch.Size([896, 896])\n",
      "32\n",
      "layers.2.mlp.gate_proj.weight torch.Size([4864, 896])\n",
      "33\n",
      "layers.2.mlp.up_proj.weight torch.Size([4864, 896])\n",
      "34\n",
      "layers.2.mlp.down_proj.weight torch.Size([896, 4864])\n",
      "35\n",
      "layers.2.input_layernorm.weight torch.Size([896])\n",
      "36\n",
      "layers.2.post_attention_layernorm.weight torch.Size([896])\n",
      "37\n",
      "layers.3.self_attn.q_proj.weight torch.Size([896, 896])\n",
      "38\n",
      "layers.3.self_attn.q_proj.bias torch.Size([896])\n",
      "39\n",
      "layers.3.self_attn.k_proj.weight torch.Size([128, 896])\n",
      "40\n",
      "layers.3.self_attn.k_proj.bias torch.Size([128])\n",
      "41\n",
      "layers.3.self_attn.v_proj.weight torch.Size([128, 896])\n",
      "42\n",
      "layers.3.self_attn.v_proj.bias torch.Size([128])\n",
      "43\n",
      "layers.3.self_attn.o_proj.weight torch.Size([896, 896])\n",
      "44\n",
      "layers.3.mlp.gate_proj.weight torch.Size([4864, 896])\n",
      "45\n",
      "layers.3.mlp.up_proj.weight torch.Size([4864, 896])\n",
      "46\n",
      "layers.3.mlp.down_proj.weight torch.Size([896, 4864])\n",
      "47\n",
      "layers.3.input_layernorm.weight torch.Size([896])\n",
      "48\n",
      "layers.3.post_attention_layernorm.weight torch.Size([896])\n",
      "49\n",
      "layers.4.self_attn.q_proj.weight torch.Size([896, 896])\n",
      "50\n",
      "layers.4.self_attn.q_proj.bias torch.Size([896])\n",
      "51\n",
      "layers.4.self_attn.k_proj.weight torch.Size([128, 896])\n",
      "52\n",
      "layers.4.self_attn.k_proj.bias torch.Size([128])\n",
      "53\n",
      "layers.4.self_attn.v_proj.weight torch.Size([128, 896])\n",
      "54\n",
      "layers.4.self_attn.v_proj.bias torch.Size([128])\n",
      "55\n",
      "layers.4.self_attn.o_proj.weight torch.Size([896, 896])\n",
      "56\n",
      "layers.4.mlp.gate_proj.weight torch.Size([4864, 896])\n",
      "57\n",
      "layers.4.mlp.up_proj.weight torch.Size([4864, 896])\n",
      "58\n",
      "layers.4.mlp.down_proj.weight torch.Size([896, 4864])\n",
      "59\n",
      "layers.4.input_layernorm.weight torch.Size([896])\n",
      "60\n",
      "layers.4.post_attention_layernorm.weight torch.Size([896])\n",
      "61\n",
      "layers.5.self_attn.q_proj.weight torch.Size([896, 896])\n",
      "62\n",
      "layers.5.self_attn.q_proj.bias torch.Size([896])\n",
      "63\n",
      "layers.5.self_attn.k_proj.weight torch.Size([128, 896])\n",
      "64\n",
      "layers.5.self_attn.k_proj.bias torch.Size([128])\n",
      "65\n",
      "layers.5.self_attn.v_proj.weight torch.Size([128, 896])\n",
      "66\n",
      "layers.5.self_attn.v_proj.bias torch.Size([128])\n",
      "67\n",
      "layers.5.self_attn.o_proj.weight torch.Size([896, 896])\n",
      "68\n",
      "layers.5.mlp.gate_proj.weight torch.Size([4864, 896])\n",
      "69\n",
      "layers.5.mlp.up_proj.weight torch.Size([4864, 896])\n",
      "70\n",
      "layers.5.mlp.down_proj.weight torch.Size([896, 4864])\n",
      "71\n",
      "layers.5.input_layernorm.weight torch.Size([896])\n",
      "72\n",
      "layers.5.post_attention_layernorm.weight torch.Size([896])\n",
      "73\n",
      "layers.6.self_attn.q_proj.weight torch.Size([896, 896])\n",
      "74\n",
      "layers.6.self_attn.q_proj.bias torch.Size([896])\n",
      "75\n",
      "layers.6.self_attn.k_proj.weight torch.Size([128, 896])\n",
      "76\n",
      "layers.6.self_attn.k_proj.bias torch.Size([128])\n",
      "77\n",
      "layers.6.self_attn.v_proj.weight torch.Size([128, 896])\n",
      "78\n",
      "layers.6.self_attn.v_proj.bias torch.Size([128])\n",
      "79\n",
      "layers.6.self_attn.o_proj.weight torch.Size([896, 896])\n",
      "80\n",
      "layers.6.mlp.gate_proj.weight torch.Size([4864, 896])\n",
      "81\n",
      "layers.6.mlp.up_proj.weight torch.Size([4864, 896])\n",
      "82\n",
      "layers.6.mlp.down_proj.weight torch.Size([896, 4864])\n",
      "83\n",
      "layers.6.input_layernorm.weight torch.Size([896])\n",
      "84\n",
      "layers.6.post_attention_layernorm.weight torch.Size([896])\n",
      "85\n",
      "layers.7.self_attn.q_proj.weight torch.Size([896, 896])\n",
      "86\n",
      "layers.7.self_attn.q_proj.bias torch.Size([896])\n",
      "87\n",
      "layers.7.self_attn.k_proj.weight torch.Size([128, 896])\n",
      "88\n",
      "layers.7.self_attn.k_proj.bias torch.Size([128])\n",
      "89\n",
      "layers.7.self_attn.v_proj.weight torch.Size([128, 896])\n",
      "90\n",
      "layers.7.self_attn.v_proj.bias torch.Size([128])\n",
      "91\n",
      "layers.7.self_attn.o_proj.weight torch.Size([896, 896])\n",
      "92\n",
      "layers.7.mlp.gate_proj.weight torch.Size([4864, 896])\n",
      "93\n",
      "layers.7.mlp.up_proj.weight torch.Size([4864, 896])\n",
      "94\n",
      "layers.7.mlp.down_proj.weight torch.Size([896, 4864])\n",
      "95\n",
      "layers.7.input_layernorm.weight torch.Size([896])\n",
      "96\n",
      "layers.7.post_attention_layernorm.weight torch.Size([896])\n",
      "97\n",
      "layers.8.self_attn.q_proj.weight torch.Size([896, 896])\n",
      "98\n",
      "layers.8.self_attn.q_proj.bias torch.Size([896])\n",
      "99\n",
      "layers.8.self_attn.k_proj.weight torch.Size([128, 896])\n",
      "100\n",
      "layers.8.self_attn.k_proj.bias torch.Size([128])\n",
      "101\n",
      "layers.8.self_attn.v_proj.weight torch.Size([128, 896])\n",
      "102\n",
      "layers.8.self_attn.v_proj.bias torch.Size([128])\n",
      "103\n",
      "layers.8.self_attn.o_proj.weight torch.Size([896, 896])\n",
      "104\n",
      "layers.8.mlp.gate_proj.weight torch.Size([4864, 896])\n",
      "105\n",
      "layers.8.mlp.up_proj.weight torch.Size([4864, 896])\n",
      "106\n",
      "layers.8.mlp.down_proj.weight torch.Size([896, 4864])\n",
      "107\n",
      "layers.8.input_layernorm.weight torch.Size([896])\n",
      "108\n",
      "layers.8.post_attention_layernorm.weight torch.Size([896])\n",
      "109\n",
      "layers.9.self_attn.q_proj.weight torch.Size([896, 896])\n",
      "110\n",
      "layers.9.self_attn.q_proj.bias torch.Size([896])\n",
      "111\n",
      "layers.9.self_attn.k_proj.weight torch.Size([128, 896])\n",
      "112\n",
      "layers.9.self_attn.k_proj.bias torch.Size([128])\n",
      "113\n",
      "layers.9.self_attn.v_proj.weight torch.Size([128, 896])\n",
      "114\n",
      "layers.9.self_attn.v_proj.bias torch.Size([128])\n",
      "115\n",
      "layers.9.self_attn.o_proj.weight torch.Size([896, 896])\n",
      "116\n",
      "layers.9.mlp.gate_proj.weight torch.Size([4864, 896])\n",
      "117\n",
      "layers.9.mlp.up_proj.weight torch.Size([4864, 896])\n",
      "118\n",
      "layers.9.mlp.down_proj.weight torch.Size([896, 4864])\n",
      "119\n",
      "layers.9.input_layernorm.weight torch.Size([896])\n",
      "120\n",
      "layers.9.post_attention_layernorm.weight torch.Size([896])\n",
      "121\n",
      "layers.10.self_attn.q_proj.weight torch.Size([896, 896])\n",
      "122\n",
      "layers.10.self_attn.q_proj.bias torch.Size([896])\n",
      "123\n",
      "layers.10.self_attn.k_proj.weight torch.Size([128, 896])\n",
      "124\n",
      "layers.10.self_attn.k_proj.bias torch.Size([128])\n",
      "125\n",
      "layers.10.self_attn.v_proj.weight torch.Size([128, 896])\n",
      "126\n",
      "layers.10.self_attn.v_proj.bias torch.Size([128])\n",
      "127\n",
      "layers.10.self_attn.o_proj.weight torch.Size([896, 896])\n",
      "128\n",
      "layers.10.mlp.gate_proj.weight torch.Size([4864, 896])\n",
      "129\n",
      "layers.10.mlp.up_proj.weight torch.Size([4864, 896])\n",
      "130\n",
      "layers.10.mlp.down_proj.weight torch.Size([896, 4864])\n",
      "131\n",
      "layers.10.input_layernorm.weight torch.Size([896])\n",
      "132\n",
      "layers.10.post_attention_layernorm.weight torch.Size([896])\n",
      "133\n",
      "layers.11.self_attn.q_proj.weight torch.Size([896, 896])\n",
      "134\n",
      "layers.11.self_attn.q_proj.bias torch.Size([896])\n",
      "135\n",
      "layers.11.self_attn.k_proj.weight torch.Size([128, 896])\n",
      "136\n",
      "layers.11.self_attn.k_proj.bias torch.Size([128])\n",
      "137\n",
      "layers.11.self_attn.v_proj.weight torch.Size([128, 896])\n",
      "138\n",
      "layers.11.self_attn.v_proj.bias torch.Size([128])\n",
      "139\n",
      "layers.11.self_attn.o_proj.weight torch.Size([896, 896])\n",
      "140\n",
      "layers.11.mlp.gate_proj.weight torch.Size([4864, 896])\n",
      "141\n",
      "layers.11.mlp.up_proj.weight torch.Size([4864, 896])\n",
      "142\n",
      "layers.11.mlp.down_proj.weight torch.Size([896, 4864])\n",
      "143\n",
      "layers.11.input_layernorm.weight torch.Size([896])\n",
      "144\n",
      "layers.11.post_attention_layernorm.weight torch.Size([896])\n",
      "145\n",
      "layers.12.self_attn.q_proj.weight torch.Size([896, 896])\n",
      "146\n",
      "layers.12.self_attn.q_proj.bias torch.Size([896])\n",
      "147\n",
      "layers.12.self_attn.k_proj.weight torch.Size([128, 896])\n",
      "148\n",
      "layers.12.self_attn.k_proj.bias torch.Size([128])\n",
      "149\n",
      "layers.12.self_attn.v_proj.weight torch.Size([128, 896])\n",
      "150\n",
      "layers.12.self_attn.v_proj.bias torch.Size([128])\n",
      "151\n",
      "layers.12.self_attn.o_proj.weight torch.Size([896, 896])\n",
      "152\n",
      "layers.12.mlp.gate_proj.weight torch.Size([4864, 896])\n",
      "153\n",
      "layers.12.mlp.up_proj.weight torch.Size([4864, 896])\n",
      "154\n",
      "layers.12.mlp.down_proj.weight torch.Size([896, 4864])\n",
      "155\n",
      "layers.12.input_layernorm.weight torch.Size([896])\n",
      "156\n",
      "layers.12.post_attention_layernorm.weight torch.Size([896])\n",
      "157\n",
      "layers.13.self_attn.q_proj.weight torch.Size([896, 896])\n",
      "158\n",
      "layers.13.self_attn.q_proj.bias torch.Size([896])\n",
      "159\n",
      "layers.13.self_attn.k_proj.weight torch.Size([128, 896])\n",
      "160\n",
      "layers.13.self_attn.k_proj.bias torch.Size([128])\n",
      "161\n",
      "layers.13.self_attn.v_proj.weight torch.Size([128, 896])\n",
      "162\n",
      "layers.13.self_attn.v_proj.bias torch.Size([128])\n",
      "163\n",
      "layers.13.self_attn.o_proj.weight torch.Size([896, 896])\n",
      "164\n",
      "layers.13.mlp.gate_proj.weight torch.Size([4864, 896])\n",
      "165\n",
      "layers.13.mlp.up_proj.weight torch.Size([4864, 896])\n",
      "166\n",
      "layers.13.mlp.down_proj.weight torch.Size([896, 4864])\n",
      "167\n",
      "layers.13.input_layernorm.weight torch.Size([896])\n",
      "168\n",
      "layers.13.post_attention_layernorm.weight torch.Size([896])\n",
      "169\n",
      "layers.14.self_attn.q_proj.weight torch.Size([896, 896])\n",
      "170\n",
      "layers.14.self_attn.q_proj.bias torch.Size([896])\n",
      "171\n",
      "layers.14.self_attn.k_proj.weight torch.Size([128, 896])\n",
      "172\n",
      "layers.14.self_attn.k_proj.bias torch.Size([128])\n",
      "173\n",
      "layers.14.self_attn.v_proj.weight torch.Size([128, 896])\n",
      "174\n",
      "layers.14.self_attn.v_proj.bias torch.Size([128])\n",
      "175\n",
      "layers.14.self_attn.o_proj.weight torch.Size([896, 896])\n",
      "176\n",
      "layers.14.mlp.gate_proj.weight torch.Size([4864, 896])\n",
      "177\n",
      "layers.14.mlp.up_proj.weight torch.Size([4864, 896])\n",
      "178\n",
      "layers.14.mlp.down_proj.weight torch.Size([896, 4864])\n",
      "179\n",
      "layers.14.input_layernorm.weight torch.Size([896])\n",
      "180\n",
      "layers.14.post_attention_layernorm.weight torch.Size([896])\n",
      "181\n",
      "layers.15.self_attn.q_proj.weight torch.Size([896, 896])\n",
      "182\n",
      "layers.15.self_attn.q_proj.bias torch.Size([896])\n",
      "183\n",
      "layers.15.self_attn.k_proj.weight torch.Size([128, 896])\n",
      "184\n",
      "layers.15.self_attn.k_proj.bias torch.Size([128])\n",
      "185\n",
      "layers.15.self_attn.v_proj.weight torch.Size([128, 896])\n",
      "186\n",
      "layers.15.self_attn.v_proj.bias torch.Size([128])\n",
      "187\n",
      "layers.15.self_attn.o_proj.weight torch.Size([896, 896])\n",
      "188\n",
      "layers.15.mlp.gate_proj.weight torch.Size([4864, 896])\n",
      "189\n",
      "layers.15.mlp.up_proj.weight torch.Size([4864, 896])\n",
      "190\n",
      "layers.15.mlp.down_proj.weight torch.Size([896, 4864])\n",
      "191\n",
      "layers.15.input_layernorm.weight torch.Size([896])\n",
      "192\n",
      "layers.15.post_attention_layernorm.weight torch.Size([896])\n",
      "193\n",
      "layers.16.self_attn.q_proj.weight torch.Size([896, 896])\n",
      "194\n",
      "layers.16.self_attn.q_proj.bias torch.Size([896])\n",
      "195\n",
      "layers.16.self_attn.k_proj.weight torch.Size([128, 896])\n",
      "196\n",
      "layers.16.self_attn.k_proj.bias torch.Size([128])\n",
      "197\n",
      "layers.16.self_attn.v_proj.weight torch.Size([128, 896])\n",
      "198\n",
      "layers.16.self_attn.v_proj.bias torch.Size([128])\n",
      "199\n",
      "layers.16.self_attn.o_proj.weight torch.Size([896, 896])\n",
      "200\n",
      "layers.16.mlp.gate_proj.weight torch.Size([4864, 896])\n",
      "201\n",
      "layers.16.mlp.up_proj.weight torch.Size([4864, 896])\n",
      "202\n",
      "layers.16.mlp.down_proj.weight torch.Size([896, 4864])\n",
      "203\n",
      "layers.16.input_layernorm.weight torch.Size([896])\n",
      "204\n",
      "layers.16.post_attention_layernorm.weight torch.Size([896])\n",
      "205\n",
      "layers.17.self_attn.q_proj.weight torch.Size([896, 896])\n",
      "206\n",
      "layers.17.self_attn.q_proj.bias torch.Size([896])\n",
      "207\n",
      "layers.17.self_attn.k_proj.weight torch.Size([128, 896])\n",
      "208\n",
      "layers.17.self_attn.k_proj.bias torch.Size([128])\n",
      "209\n",
      "layers.17.self_attn.v_proj.weight torch.Size([128, 896])\n",
      "210\n",
      "layers.17.self_attn.v_proj.bias torch.Size([128])\n",
      "211\n",
      "layers.17.self_attn.o_proj.weight torch.Size([896, 896])\n",
      "212\n",
      "layers.17.mlp.gate_proj.weight torch.Size([4864, 896])\n",
      "213\n",
      "layers.17.mlp.up_proj.weight torch.Size([4864, 896])\n",
      "214\n",
      "layers.17.mlp.down_proj.weight torch.Size([896, 4864])\n",
      "215\n",
      "layers.17.input_layernorm.weight torch.Size([896])\n",
      "216\n",
      "layers.17.post_attention_layernorm.weight torch.Size([896])\n",
      "217\n",
      "layers.18.self_attn.q_proj.weight torch.Size([896, 896])\n",
      "218\n",
      "layers.18.self_attn.q_proj.bias torch.Size([896])\n",
      "219\n",
      "layers.18.self_attn.k_proj.weight torch.Size([128, 896])\n",
      "220\n",
      "layers.18.self_attn.k_proj.bias torch.Size([128])\n",
      "221\n",
      "layers.18.self_attn.v_proj.weight torch.Size([128, 896])\n",
      "222\n",
      "layers.18.self_attn.v_proj.bias torch.Size([128])\n",
      "223\n",
      "layers.18.self_attn.o_proj.weight torch.Size([896, 896])\n",
      "224\n",
      "layers.18.mlp.gate_proj.weight torch.Size([4864, 896])\n",
      "225\n",
      "layers.18.mlp.up_proj.weight torch.Size([4864, 896])\n",
      "226\n",
      "layers.18.mlp.down_proj.weight torch.Size([896, 4864])\n",
      "227\n",
      "layers.18.input_layernorm.weight torch.Size([896])\n",
      "228\n",
      "layers.18.post_attention_layernorm.weight torch.Size([896])\n",
      "229\n",
      "layers.19.self_attn.q_proj.weight torch.Size([896, 896])\n",
      "230\n",
      "layers.19.self_attn.q_proj.bias torch.Size([896])\n",
      "231\n",
      "layers.19.self_attn.k_proj.weight torch.Size([128, 896])\n",
      "232\n",
      "layers.19.self_attn.k_proj.bias torch.Size([128])\n",
      "233\n",
      "layers.19.self_attn.v_proj.weight torch.Size([128, 896])\n",
      "234\n",
      "layers.19.self_attn.v_proj.bias torch.Size([128])\n",
      "235\n",
      "layers.19.self_attn.o_proj.weight torch.Size([896, 896])\n",
      "236\n",
      "layers.19.mlp.gate_proj.weight torch.Size([4864, 896])\n",
      "237\n",
      "layers.19.mlp.up_proj.weight torch.Size([4864, 896])\n",
      "238\n",
      "layers.19.mlp.down_proj.weight torch.Size([896, 4864])\n",
      "239\n",
      "layers.19.input_layernorm.weight torch.Size([896])\n",
      "240\n",
      "layers.19.post_attention_layernorm.weight torch.Size([896])\n",
      "241\n",
      "layers.20.self_attn.q_proj.weight torch.Size([896, 896])\n",
      "242\n",
      "layers.20.self_attn.q_proj.bias torch.Size([896])\n",
      "243\n",
      "layers.20.self_attn.k_proj.weight torch.Size([128, 896])\n",
      "244\n",
      "layers.20.self_attn.k_proj.bias torch.Size([128])\n",
      "245\n",
      "layers.20.self_attn.v_proj.weight torch.Size([128, 896])\n",
      "246\n",
      "layers.20.self_attn.v_proj.bias torch.Size([128])\n",
      "247\n",
      "layers.20.self_attn.o_proj.weight torch.Size([896, 896])\n",
      "248\n",
      "layers.20.mlp.gate_proj.weight torch.Size([4864, 896])\n",
      "249\n",
      "layers.20.mlp.up_proj.weight torch.Size([4864, 896])\n",
      "250\n",
      "layers.20.mlp.down_proj.weight torch.Size([896, 4864])\n",
      "251\n",
      "layers.20.input_layernorm.weight torch.Size([896])\n",
      "252\n",
      "layers.20.post_attention_layernorm.weight torch.Size([896])\n",
      "253\n",
      "layers.21.self_attn.q_proj.weight torch.Size([896, 896])\n",
      "254\n",
      "layers.21.self_attn.q_proj.bias torch.Size([896])\n",
      "255\n",
      "layers.21.self_attn.k_proj.weight torch.Size([128, 896])\n",
      "256\n",
      "layers.21.self_attn.k_proj.bias torch.Size([128])\n",
      "257\n",
      "layers.21.self_attn.v_proj.weight torch.Size([128, 896])\n",
      "258\n",
      "layers.21.self_attn.v_proj.bias torch.Size([128])\n",
      "259\n",
      "layers.21.self_attn.o_proj.weight torch.Size([896, 896])\n",
      "260\n",
      "layers.21.mlp.gate_proj.weight torch.Size([4864, 896])\n",
      "261\n",
      "layers.21.mlp.up_proj.weight torch.Size([4864, 896])\n",
      "262\n",
      "layers.21.mlp.down_proj.weight torch.Size([896, 4864])\n",
      "263\n",
      "layers.21.input_layernorm.weight torch.Size([896])\n",
      "264\n",
      "layers.21.post_attention_layernorm.weight torch.Size([896])\n",
      "265\n",
      "layers.22.self_attn.q_proj.weight torch.Size([896, 896])\n",
      "266\n",
      "layers.22.self_attn.q_proj.bias torch.Size([896])\n",
      "267\n",
      "layers.22.self_attn.k_proj.weight torch.Size([128, 896])\n",
      "268\n",
      "layers.22.self_attn.k_proj.bias torch.Size([128])\n",
      "269\n",
      "layers.22.self_attn.v_proj.weight torch.Size([128, 896])\n",
      "270\n",
      "layers.22.self_attn.v_proj.bias torch.Size([128])\n",
      "271\n",
      "layers.22.self_attn.o_proj.weight torch.Size([896, 896])\n",
      "272\n",
      "layers.22.mlp.gate_proj.weight torch.Size([4864, 896])\n",
      "273\n",
      "layers.22.mlp.up_proj.weight torch.Size([4864, 896])\n",
      "274\n",
      "layers.22.mlp.down_proj.weight torch.Size([896, 4864])\n",
      "275\n",
      "layers.22.input_layernorm.weight torch.Size([896])\n",
      "276\n",
      "layers.22.post_attention_layernorm.weight torch.Size([896])\n",
      "277\n",
      "layers.23.self_attn.q_proj.weight torch.Size([896, 896])\n",
      "278\n",
      "layers.23.self_attn.q_proj.bias torch.Size([896])\n",
      "279\n",
      "layers.23.self_attn.k_proj.weight torch.Size([128, 896])\n",
      "280\n",
      "layers.23.self_attn.k_proj.bias torch.Size([128])\n",
      "281\n",
      "layers.23.self_attn.v_proj.weight torch.Size([128, 896])\n",
      "282\n",
      "layers.23.self_attn.v_proj.bias torch.Size([128])\n",
      "283\n",
      "layers.23.self_attn.o_proj.weight torch.Size([896, 896])\n",
      "284\n",
      "layers.23.mlp.gate_proj.weight torch.Size([4864, 896])\n",
      "285\n",
      "layers.23.mlp.up_proj.weight torch.Size([4864, 896])\n",
      "286\n",
      "layers.23.mlp.down_proj.weight torch.Size([896, 4864])\n",
      "287\n",
      "layers.23.input_layernorm.weight torch.Size([896])\n",
      "288\n",
      "layers.23.post_attention_layernorm.weight torch.Size([896])\n",
      "289\n",
      "norm.weight torch.Size([896])\n"
     ]
    }
   ],
   "source": [
    "sd_hf = model_hf.state_dict()\n",
    "j=0\n",
    "for k, v in sd_hf.items():\n",
    "    print(j)\n",
    "    print(k, v.shape)\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33153f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d698c36d43a64091ad4600d6507a9574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82557b8ce5e24810b399ecbc6c4dfd83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f87b2a9de7934b00843b9ec2992877d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb06f1296aba4ab8b2f7ef28f18f79c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('Qwen/Qwen2-0.5B', trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6311dd34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"print('<|endoftext|>')<|endoftext|> he is a good boy\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(\"print('<|endoftext|>')<|endoftext|> he is a good boy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1b3c8868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[383, 374, 264, 1661, 8171]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"he is a good boy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b50af516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151646"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee1ce17b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[151640, 151641, 151642, 151643, 151644, 151645, 151646]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in range(151640, 151647)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73d4ab0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⍨⺟⽗<|endoftext|><|im_start|><|im_end|>'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([i for i in range(151640, 151650)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cb0c41f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4738.9375"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "151646 / 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "60ddb609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9496.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "151936 / 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d880a271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262144"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "47b7d74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "60207067",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "generator = pipeline('text-generation', 'Qwen/Qwen2-0.5B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d00ee901",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Both `max_new_tokens` (=2048) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"Hello, I'm a language model and I don't have the ability to create a new account or sign up for a service. However, I can provide you with some general information about how to create an account on a language model website.\\n\\nTo create an account on a language model website, you will need to follow these steps:\\n\\n1. Sign up for a free account: You can sign up for a free account on any language model website. This will allow you to access their services and test out their models.\\n\\n2. Create a new account: Once you have signed up for a free account, you will need to create a new account. This will involve filling out a form with your personal information and providing your payment information.\\n\\n3. Choose a language model: There are many language model websites available, so you will need to choose one that suits your needs. Some popular language model websites include Google Translate, Google Translate API, and Google Cloud Translation.\\n\\n4. Set up your account: Once you have created your account, you will need to set up your account settings. This will include your payment information, your language model, and your preferred language.\\n\\n5. Start using the language model: Once you have set up your account, you can start using the language model. You can use it to translate text, create sentences, and even generate text.\\n\\nOverall, creating an account on a language model website is a simple process that can help you get started with using their services.\\n\\nCan you provide me with some examples of language models that are popular among language model users? I want to make sure I choose the right one for my needs.\\n\\nSure, here are some popular language model websites and their features:\\n\\n1. Google Translate: This is one of the most popular language model websites, and it offers a wide range of features, including translation, machine translation, and machine translation with human feedback. 2. Google Cloud Translation: This is a cloud-based language model that offers a wide range of features, including translation, machine translation, and machine translation with human feedback. 3. Google Translate API: This is a free API that allows you to use Google Translate in your own applications. It offers a wide range of features, including translation, machine translation, and machine translation with human feedback. 4. Google Cloud Translation API: This is a free API that allows you to use Google Cloud Translation in your own applications. It offers a wide range of features, including translation, machine translation, and machine translation with human feedback. 5. Google Translate API for Python: This is a Python API that allows you to use Google Translate in your own applications. It offers a wide range of features, including translation, machine translation, and machine translation with human feedback. These are just a few examples of the many language model websites available. It's important to choose a language model that suits your needs and preferences, and to read reviews and ratings from other language model users to ensure that you choose the right one for your needs.\\n\\nCan you tell me more about the features of Google Cloud Translation API? I'm interested in using it for my own applications.\\n\\nSure, here are some of the features of Google Cloud Translation API:\\n\\n1. Translation: Google Cloud Translation API allows you to translate text from one language to another. You can use it to translate text in your own applications, such as web pages, blogs, and social media posts. 2. Machine Translation: Google Cloud Translation API allows you to use machine translation to translate text from one language to another. You can use it to translate text in your own applications, such as web pages, blogs, and social media posts. 3. Machine Translation with Human Feedback: Google Cloud Translation API allows you to use machine translation with human feedback. You can use it to translate text in your own applications, such as web pages, blogs, and social media posts, and receive human feedback on the quality of the translation. 4. Integration with Google Cloud Platform: Google Cloud Translation API integrates with Google Cloud Platform, which allows you to use it in your own applications. You can use it to translate text in your own applications, such as web pages, blogs, and social media posts. 5. API Documentation: Google Cloud Translation API provides an API documentation that includes detailed information on how to use the API, including how to use machine translation, how to use machine translation with human feedback, and how to use integration with Google Cloud Platform. Overall, Google Cloud Translation API is a powerful tool that can help you translate text in your own applications, and it provides a wide range of features that can help you achieve your translation goals.\"}]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "generator(\"Hello, I'm a language model\", max_length=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "87b58bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.encode(\"<|endoftext|>  Hello, I'm a language model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5efe4aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[151643, 220, 21927, 11, 358, 2776, 264, 4128, 1614]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "af02dda1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9707,   11,  358, 2776,  264, 4128, 1614],\n",
       "        [9707,   11,  358, 2776,  264, 4128, 1614],\n",
       "        [9707,   11,  358, 2776,  264, 4128, 1614],\n",
       "        [9707,   11,  358, 2776,  264, 4128, 1614],\n",
       "        [9707,   11,  358, 2776,  264, 4128, 1614]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.tensor(tokens).unsqueeze(0).repeat(5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8c314d",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "meta-qwen2/Qwen2-2-7b-hf is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu-211/lib/python3.10/site-packages/huggingface_hub/utils/_http.py:409\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 409\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu-211/lib/python3.10/site-packages/requests/models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: https://huggingface.co/meta-qwen2/Qwen2-2-7b-hf/resolve/main/config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu-211/lib/python3.10/site-packages/transformers/utils/hub.py:424\u001b[0m, in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(full_filenames) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    423\u001b[0m     \u001b[38;5;66;03m# This is slightly better for only 1 file\u001b[39;00m\n\u001b[0;32m--> 424\u001b[0m     \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu-211/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu-211/lib/python3.10/site-packages/huggingface_hub/file_download.py:1008\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m   1007\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1008\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[1;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[1;32m   1012\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[1;32m   1017\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[1;32m   1023\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1025\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu-211/lib/python3.10/site-packages/huggingface_hub/file_download.py:1115\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[38;5;66;03m# Otherwise, raise appropriate error\u001b[39;00m\n\u001b[0;32m-> 1115\u001b[0m     \u001b[43m_raise_on_head_call_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_call_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1117\u001b[0m \u001b[38;5;66;03m# From now on, etag, commit_hash, url and size are not None.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu-211/lib/python3.10/site-packages/huggingface_hub/file_download.py:1645\u001b[0m, in \u001b[0;36m_raise_on_head_call_error\u001b[0;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[1;32m   1640\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, (RepositoryNotFoundError, GatedRepoError)) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   1641\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(head_call_error, HfHubHTTPError) \u001b[38;5;129;01mand\u001b[39;00m head_call_error\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m401\u001b[39m\n\u001b[1;32m   1642\u001b[0m ):\n\u001b[1;32m   1643\u001b[0m     \u001b[38;5;66;03m# Repo not found or gated => let's raise the actual error\u001b[39;00m\n\u001b[1;32m   1644\u001b[0m     \u001b[38;5;66;03m# Unauthorized => likely a token issue => let's raise the actual error\u001b[39;00m\n\u001b[0;32m-> 1645\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m head_call_error\n\u001b[1;32m   1646\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu-211/lib/python3.10/site-packages/huggingface_hub/file_download.py:1533\u001b[0m, in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1532\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1533\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1534\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\n\u001b[1;32m   1535\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu-211/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu-211/lib/python3.10/site-packages/huggingface_hub/file_download.py:1450\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[1;32m   1449\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[0;32m-> 1450\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1451\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHEAD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1452\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1453\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1455\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1456\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1459\u001b[0m hf_raise_for_status(r)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu-211/lib/python3.10/site-packages/huggingface_hub/file_download.py:286\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[0;32m--> 286\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu-211/lib/python3.10/site-packages/huggingface_hub/file_download.py:310\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    309\u001b[0m response \u001b[38;5;241m=\u001b[39m http_backoff(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams, retry_on_exceptions\u001b[38;5;241m=\u001b[39m(), retry_on_status_codes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m429\u001b[39m,))\n\u001b[0;32m--> 310\u001b[0m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu-211/lib/python3.10/site-packages/huggingface_hub/utils/_http.py:459\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    450\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    451\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    452\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m https://huggingface.co/docs/huggingface_hub/authentication\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    458\u001b[0m     )\n\u001b[0;32m--> 459\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _format(RepositoryNotFoundError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m400\u001b[39m:\n",
      "\u001b[0;31mRepositoryNotFoundError\u001b[0m: 404 Client Error. (Request ID: Root=1-68b32a5e-4b5aec64579e38dc4457d766;9301958d-e010-4ce6-a2e9-ec1d8b8eadcb)\n\nRepository Not Found for url: https://huggingface.co/meta-qwen2/Qwen2-2-7b-hf/resolve/main/config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, Qwen2ForCausalLM\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mQwen2ForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmeta-qwen2/Qwen2-2-7b-hf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta-qwen2/Qwen2-2-7b-hf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHey, are you conscious? Can you talk to me?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu-211/lib/python3.10/site-packages/transformers/modeling_utils.py:279\u001b[0m, in \u001b[0;36mrestore_default_torch_dtype.<locals>._wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m old_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mget_default_dtype()\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 279\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    281\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_default_dtype(old_dtype)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu-211/lib/python3.10/site-packages/transformers/modeling_utils.py:4078\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4075\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m commit_hash \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4076\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[1;32m   4077\u001b[0m         \u001b[38;5;66;03m# We make a call to the config file first (which may be absent) to get the commit hash as soon as possible\u001b[39;00m\n\u001b[0;32m-> 4078\u001b[0m         resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4079\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4080\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4081\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4082\u001b[0m \u001b[43m            \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4083\u001b[0m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4084\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4085\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4086\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4087\u001b[0m \u001b[43m            \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4088\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_gated_repo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   4089\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_missing_entries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   4090\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_connection_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   4091\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4092\u001b[0m         commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[1;32m   4093\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu-211/lib/python3.10/site-packages/transformers/utils/hub.py:266\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcached_file\u001b[39m(\n\u001b[1;32m    209\u001b[0m     path_or_repo_id: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike],\n\u001b[1;32m    210\u001b[0m     filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    212\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    213\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;124;03m    Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m     file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m     file \u001b[38;5;241m=\u001b[39m file[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m file\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m file\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu-211/lib/python3.10/site-packages/transformers/utils/hub.py:456\u001b[0m, in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;66;03m# We cannot recover from them\u001b[39;00m\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, RepositoryNotFoundError) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, GatedRepoError):\n\u001b[0;32m--> 456\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[1;32m    457\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a local folder and is not a valid model identifier \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    458\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlisted on \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf this is a private repository, make sure to pass a token \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    459\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhaving permission to this repo either by logging in with `huggingface-cli login` or by passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    460\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`token=<your_token>`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    461\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, RevisionNotFoundError):\n\u001b[1;32m    463\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[1;32m    464\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid git identifier (branch name, tag name or commit id) that exists \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    465\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor this model name. Check the model page at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    466\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for available revisions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    467\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mOSError\u001b[0m: meta-qwen2/Qwen2-2-7b-hf is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, Qwen2ForCausalLM\n",
    "\n",
    "model = Qwen2ForCausalLM.from_pretrained(\"meta-qwen2/Qwen2-2-0.5b-hf\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-qwen2/Qwen2-2-0.5b-hf\")\n",
    "\n",
    "prompt = \"Hey, are you conscious? Can you talk to me?\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Generate\n",
    "generate_ids = model.generate(inputs.input_ids, max_length=30)\n",
    "tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2f1d7dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <|endoftext|>  Hello, I'm a language model of of of of of of of of of of of of of of of of of of of of of\n",
      "> <|endoftext|>  Hello, I'm a language model of of of of of of of of of of of of of of of of of of of of of\n",
      "> <|endoftext|>  Hello, I'm a language model of of of of of of of of of of of of of of of of of of of of of\n",
      "> <|endoftext|>  Hello, I'm a language model of of of of of of of of of of of of of of of of of of of of of\n",
      "> <|endoftext|>  Hello, I'm a language model of of of of of of of of of of of of of of of of of of of of of\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "\n",
    "model = Qwen2Model.from_pretrained('Qwen/Qwen2-0.5B')\n",
    "model.eval()\n",
    "model.to('cuda')\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "tokens = [151643, 220, 21927, 11, 358, 2776, 264, 4128, 1614]# \"Hello, I'm a language model,\"\n",
    "tokens = torch.tensor(tokens, dtype=torch.long) # (8,)\n",
    "tokens = tokens.unsqueeze(0).repeat(5, 1) # (5, 8)\n",
    "x = tokens.to('cuda')\n",
    "\n",
    "# generate!\n",
    "while x.size(1) < 30: # max_length=30\n",
    "    # forward the model to get the logits\n",
    "    with torch.no_grad():\n",
    "        logits = model(x)[0] # (B, T, vocab_size)\n",
    "        # take the logits at the last position\n",
    "        logits = logits[:, -1, :] # (B, vocab_size)\n",
    "        # get the probabilities\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        # do top-k sampling of 50 (huggingface pipeline default)\n",
    "        # topk_probs here becomes (5, 50), topk_indices is (5, 50)\n",
    "        topk_probs, topk_indices = torch.topk(probs, 50, dim=-1)\n",
    "        # select a token from the top-k probabilities\n",
    "        # note: multinomial does not demand the input to sum to 1\n",
    "        ix = torch.multinomial(topk_probs, 1) # (B, 1)\n",
    "        # gather the corresponding indices\n",
    "        xcol = torch.gather(topk_indices, -1, ix) # (B, 1)\n",
    "        # append to the sequence\n",
    "        x = torch.cat((x, xcol), dim=1)\n",
    "\n",
    "# print the generated text\n",
    "# import tiktoken\n",
    "# enc = tiktoken.get_encoding('gpt2')\n",
    "for i in range(5):\n",
    "    tokens = x[i, :30].tolist()\n",
    "    decoded = tokenizer.decode(tokens)\n",
    "    print(\">\", decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9b6d3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu-211",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
